{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_lg\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5un55REVX4ff",
        "outputId": "64cfb738-6eb8-4e0e-8b9a-5760a086f090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "DOEYyN-isbZX",
        "outputId": "1bf6d124-b680-425f-8bc8-5c1ff91ed191"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-47ccba274b6a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E62C6UfMucOt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import spacy\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from collections import defaultdict\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWYpoGhhSeCR"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------------------------------------------\n",
        "#files_paths\n",
        "#files_path[0] quries (questions to test the model )  name: cran.all.1400\n",
        "#files_path[1] label - cran.qry sorguId document Id name: cran.qry\n",
        "#files_paths[2]) name :cranqrel instructiions\n",
        "#files_path[3] are the articals summeries\n",
        "#------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJfop1gys1JM"
      },
      "outputs": [],
      "source": [
        "def read_file(file_path):\n",
        "  with open(file_path,\"r\",encoding=\"utf-8\") as file:\n",
        "    file = file.read()\n",
        "    #print(file)\n",
        "    return file\n",
        "\n",
        "def get_files_names(folder_path):\n",
        "    files = []\n",
        "    for file in os.listdir(folder_path):\n",
        "      path = os.path.join(folder_path, file)\n",
        "      files.append(path)\n",
        "    return files\n",
        "#print(read_file(files_paths[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "X6AzJPb5SiLi"
      },
      "outputs": [],
      "source": [
        "def list_collection_files(folder_path):\n",
        "  docs=[]\n",
        "  files_paths = get_files_names(folder_path)\n",
        "  for file_path in files_paths:\n",
        "    print(f\"path : {file_path} file loading ...................\")\n",
        "    #doc = read_file(file_path)[:1000]\n",
        "    doc = read_file(file_path)\n",
        "    docs.append(doc)\n",
        "    #print(doc)\n",
        "  return docs\n",
        "ctr=0\n",
        "folder_path = \"/content/drive/MyDrive/datas/cran\"\n",
        "files_txts_list = list_collection_files(folder_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dkcDiFwFlVu"
      },
      "outputs": [],
      "source": [
        "def load_docs(pattern,file_path):\n",
        "  txt = read_file(file_path)\n",
        "  print(files_paths[0])\n",
        "  matches = re.findall(pattern, txt, re.DOTALL)\n",
        "  return matches\n",
        "\n",
        "Ar_qu_pairs = np.empty((0,3),dtype=object)\n",
        "article_dic={}\n",
        "query_dic={}\n",
        "patterns= [r'I (\\d{3})([\\s\\S]*?)(?=\\.I \\d{3}|$)',r\"(\\d) (\\d{1,}) (-\\d|\\d)\",\"\",r'\\.I (\\d+)\\n(.+?)(?=(?:\\n\\.I \\d+)|\\Z)']\n",
        "files_paths = get_files_names(folder_path)\n",
        "for idx in range(len(files_paths)):\n",
        "  if idx!=2:\n",
        "    matches =  load_docs(patterns[idx],files_paths[idx])\n",
        "    if idx ==0:\n",
        "      #files_path[0] quries (questions to test the model )  name: cran.all.1400\n",
        "      for matching in matches :\n",
        "         query_dic[int(matching[0])]=matching[1][4:-1]\n",
        "    elif idx==1:\n",
        "       for matching in matches:\n",
        "        #files_path[1] label - cran.qry sorguId document Id name: cran.qry\n",
        "        Ar_qu_pairs = np.append(Ar_qu_pairs, [[matching[0], matching[1], matching[2]]], axis=0)\n",
        "    elif idx ==3 :\n",
        "      #print(\"articales  matches size \", len(matches ))\n",
        "      #files_path[3] are the articals summeries\n",
        "      for matching in matches:\n",
        "\n",
        "        article_dic[int(matching[0])]=matching[1]\n",
        "\n",
        "print(len(article_dic))\n",
        "print(len(query_dic))\n",
        "print(Ar_qu_pairs.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efzHUChxQ9pD"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word.isalnum()]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    porter_stemmer = PorterStemmer()\n",
        "    tokens = [porter_stemmer.stem(word) for word in tokens]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFA3mA79LSf9"
      },
      "outputs": [],
      "source": [
        "def build_inverted_index(docs):\n",
        "    inverted_index = {}\n",
        "    for doc_id, text in docs.items():\n",
        "        tokens = preprocess_text(text)\n",
        "        word = {}\n",
        "        for token in tokens:\n",
        "            if token not in word:\n",
        "                word[token] = 0\n",
        "            word[token] += 1\n",
        "\n",
        "        for token, count in word.items():\n",
        "            if token not in inverted_index:\n",
        "                inverted_index[token] = {'docId_and_freq': [], '_term_freq_over_docs': 0}\n",
        "            inverted_index[token]['docId_and_freq'].append([doc_id, count])\n",
        "            inverted_index[token]['_term_freq_over_docs'] += count\n",
        "    return inverted_index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDr63m_3WMXo"
      },
      "source": [
        "testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Or5w7WlIVGiz"
      },
      "outputs": [],
      "source": [
        "def get_posting_list(inverted_index, query):\n",
        "  posting_lists = []\n",
        "  for term in query:\n",
        "      if term in inverted_index:\n",
        "          posting_lists.append(inverted_index[term]['docId_and_freq'])\n",
        "  return posting_lists\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-pmgwbqC8fW"
      },
      "outputs": [],
      "source": [
        "def merge_algorithm(pos1 ,pos2):\n",
        "  p1,p2= 0,0\n",
        "  answer = []\n",
        "  while ((p1 is not None) and ( p2 is not None)):\n",
        "    if p1 < len(pos1) and p2 < len(pos2):\n",
        "      docsID1,freq1=pos1[p1]\n",
        "      docsID2,freq2 =pos2[p2]\n",
        "      if docsID1==docsID2 :\n",
        "        answer.append([docsID1,max(freq1,freq2)])\n",
        "        p1+=1\n",
        "        p2+=1\n",
        "      elif docsID1<docsID2:\n",
        "        p1+=1\n",
        "      else:\n",
        "        p2+=1\n",
        "    elif (p1>=len(pos1) ) or (p2>=len(pos2)):\n",
        "      p1= None\n",
        "      p2 = None\n",
        "  return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbw-orPxcJAn"
      },
      "outputs": [],
      "source": [
        "  vectors= build_inverted_index(article_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrDgdsO8HLYC"
      },
      "outputs": [],
      "source": [
        "def bool_retriving(inverted_index,query):\n",
        "  query_after_processsing= preprocess_text(query)\n",
        "  posting_lists = get_posting_list(inverted_index, query_after_processsing)\n",
        "  if not posting_lists:\n",
        "      return []\n",
        "  result = posting_lists[0]\n",
        "  for posting in posting_lists[1:]:\n",
        "      result = merge_algorithm(result, posting)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRW92nCuHl7Q"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7STICuZOdkUU"
      },
      "outputs": [],
      "source": [
        "def tf_clc(inverted_index):\n",
        "    tf = {}\n",
        "    for word, docIds_freq in inverted_index.items():\n",
        "        for docId, freq in docIds_freq['docId_and_freq']:\n",
        "            if docId not in tf:\n",
        "                tf[docId] = {}\n",
        "            tf[docId][word] = freq\n",
        "    return tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-ZqlowXa-H3"
      },
      "outputs": [],
      "source": [
        "def df_clc(inverted_index, word):\n",
        "    df = len(inverted_index[word]['docId_and_freq'])\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwlbY5kSgImy"
      },
      "outputs": [],
      "source": [
        "def idf_clc(docs , inverted_index):\n",
        "  N=0\n",
        "  idf={}\n",
        "  total_tokens_length = [len(preprocess_text(doc)) for _, doc in article_dic.items()]\n",
        "  for doc_len in total_tokens_length:\n",
        "    N+=doc_len\n",
        "  for word, docs_freqs in inverted_index.items():\n",
        "    df = df_clc(inverted_index, word)\n",
        "    if df:\n",
        "      idf[word] = math.log(N / df)\n",
        "    else:\n",
        "       idf[word]  = 0\n",
        "  return idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJcnSeDXEBk9"
      },
      "outputs": [],
      "source": [
        "def tfidf_clc(tf, idf):\n",
        "    tf_idf = {}\n",
        "    for docId, words in tf.items():\n",
        "        tf_idf[docId] = {}\n",
        "        for word, tf_value in words.items():\n",
        "            tf_idf[docId][word] = tf_value * idf.get(word, 0)\n",
        "    return tf_idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HnFN3OuAQ6V"
      },
      "outputs": [],
      "source": [
        "\n",
        "def test_tfidf(inverted_index,article_dic,query):\n",
        "  query_tf = {}\n",
        "  query_tf_idf = {}\n",
        "  #---------------tf-idf--------------------------------------------\n",
        "  tf = tf_clc(inverted_index)\n",
        "  idf = idf_clc(article_dic, inverted_index)\n",
        "  tfidf = tfidf_clc(tf, idf)\n",
        "\n",
        "  #----------------------process query --------------------------\n",
        "  qi = preprocess_text(query)\n",
        "  for tkn in qi:\n",
        "      if tkn not in query_tf:\n",
        "          query_tf[tkn] = 0\n",
        "      query_tf[tkn] += 1\n",
        "\n",
        "  for word, freq_over_q in query_tf.items():\n",
        "      query_tf_idf[word] = freq_over_q * idf.get(word, 0)\n",
        "  return query_tf_idf\n",
        "\n",
        "\n",
        "query= input(\"enter ur qeury :\")\n",
        "test_tfidf(vectors,article_dic,query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLZT3qNn0ZY1"
      },
      "outputs": [],
      "source": [
        "def cosin_similarity(vec1, vec2):\n",
        "  common_words = []\n",
        "  multi_vecs = 0\n",
        "  for key in vec1.keys():\n",
        "      if key in vec2.keys():\n",
        "          common_words.append(key)\n",
        "  for common_word in common_words:\n",
        "      multi_vecs += vec2[common_word] * vec1[common_word]\n",
        "  v1_intensity = math.sqrt(sum([x**2 for x in vec2.values()]))\n",
        "  v2_intensity = math.sqrt(sum([x**2 for x in vec1.values()]))\n",
        "  multi_intensities = v1_intensity * v2_intensity\n",
        "  if multi_intensities != 0:\n",
        "      cos_theta = multi_vecs / multi_intensities\n",
        "  else:\n",
        "      cos_theta = 0.0\n",
        "  return cos_theta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx8TQQ8cl6qM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BUeTpjYL6Dd"
      },
      "outputs": [],
      "source": [
        "def computation(inverted_index, article_dic, query):\n",
        "    query_tf = {}\n",
        "    query_tf_idf = {}\n",
        "    cos_similarities = {}\n",
        "\n",
        "    #---------------tf-idf--------------------------------------------\n",
        "    tf = tf_clc(inverted_index)\n",
        "    idf = idf_clc(article_dic, inverted_index)\n",
        "    tfidf = tfidf_clc(tf, idf)\n",
        "\n",
        "    #----------------------process query --------------------------\n",
        "    qi = preprocess_text(query)\n",
        "    for tkn in qi:\n",
        "        if tkn not in query_tf:\n",
        "            query_tf[tkn] = 0\n",
        "        query_tf[tkn] += 1\n",
        "\n",
        "    for word, freq_over_q in query_tf.items():\n",
        "        query_tf_idf[word] = freq_over_q * idf.get(word, 0)\n",
        "\n",
        "    for id, tf_idf in tfidf.items():\n",
        "        cos_similarities[id] = cosin_similarity(query_tf_idf, tf_idf)\n",
        "    return cos_similarities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans= []\n",
        "query= input(\"enter ur qeury :\")\n",
        "\n",
        "res= bool_retriving(vectors,query)\n",
        "res.sort(key=lambda x: x[1]) # Sort the res list in place\n",
        "print(res) # Print the sorted res list"
      ],
      "metadata": {
        "id": "xg6mWZzVKzV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "query= input(\"enter ur qeury :\")\n",
        "answer_list=[]\n",
        "ans_dict = computation(vectors,article_dic,query)\n",
        "for docId, relevance in ans_dict.items():\n",
        "  if relevance>0.4:\n",
        "    answer_list.append(docId)\n",
        "print(answer_list)\n"
      ],
      "metadata": {
        "id": "SKy0dgGjLIHb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}